<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>SenyasFSL WebView Hands</title>

  <!-- MediaPipe Dependencies -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    body {
      margin: 0;
      background: black;
      overflow: hidden;
    }
    video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      transform: scaleX(-1); /* Mirror for selfie */
    }
  </style>
</head>
<body>
  <video id="input_video" autoplay playsinline muted></video>

  <script type="module">
    const videoElement = document.getElementById('input_video');
    const SEQ_LENGTH = 30;
    let sequence = [];
    let lastSent = 0;

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user', width: 640, height: 480 },
          audio: false,
        });
        videoElement.srcObject = stream;
        await new Promise((resolve) => (videoElement.onloadedmetadata = resolve));
        console.log("‚úÖ Front camera ready");
        sendToReactNative("‚úÖ Front camera initialized");
      } catch (err) {
        console.error("üö´ Camera access error:", err);
        sendToReactNative("üö´ Camera access error: " + err.message);
      }
    }

    // Setup MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7,
    });

    hands.onResults(async (results) => {
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0].flatMap(pt => [pt.x, pt.y, pt.z]);
        sequence.push(landmarks);
        if (sequence.length > SEQ_LENGTH) sequence.shift();

        const now = Date.now();
        if (sequence.length === SEQ_LENGTH && now - lastSent > 1000) {
          lastSent = now;
          try {
            const res = await fetch("http://192.168.0.106:8000/predict", {  // üëà CHANGE THIS TO YOUR BACKEND IP
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ sequence }),
            });
            const data = await res.json();
            console.log("üß† Prediction:", data);
            sendToReactNative(JSON.stringify(data));
          } catch (err) {
            console.error("‚ùå Prediction error:", err);
            sendToReactNative("‚ùå Prediction error: " + err.message);
          }
        }
      }
    });

    async function init() {
      await setupCamera();
      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({ image: videoElement });
        },
        width: 640,
        height: 480,
      });
      camera.start();
    }

    init();

    // Send messages to React Native
    function sendToReactNative(msg) {
      if (window.ReactNativeWebView) {
        window.ReactNativeWebView.postMessage(msg);
      } else {
        console.log("‚ÑπÔ∏è RN bridge not available:", msg);
      }
    }
  </script>
</body>
</html>

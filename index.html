<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>SenyasFSL - Hands Recognizer</title>

  <!-- MediaPipe dependencies -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    html, body {
      margin: 0;
      background: black;
      height: 100%;
    }
    video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      transform: scaleX(-1);
    }
  </style>
</head>
<body>
  <video id="input_video" autoplay playsinline muted></video>

  <script type="module">
    /******************** CONFIGURATION ********************/
    const SEQ_LENGTH = 30;
    const SAMPLE_INTERVAL_MS = 50;
    const PREDICT_THROTTLE_MS = 800;
    const SMOOTHING_ALPHA = 0.6;
    const FLIP_X = true;

    // 🧠 Configurable via injected JS from React Native
    const HAND_MODE = window.HAND_MODE || "one";   // "one" or "two"
    const MODEL_NAME = window.MODEL_NAME || "letters";
    const BACKEND_URL = `https://senyasfsl-api-tw67.onrender.com/predict/${MODEL_NAME}`;
    /*********************************************************/

    const videoElement = document.getElementById("input_video");

    let seqRight = [];
    let seqLeft = [];
    let lastSampleTs = 0;
    let lastSentTs = 0;
    let cameraInstance = null;
    let prevSmoothR = null, prevSmoothL = null;

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user", width: 640, height: 480 },
          audio: false,
        });
        videoElement.srcObject = stream;
        await new Promise((res) => (videoElement.onloadedmetadata = res));
        sendToReactNative("✅ Camera ready");
      } catch (err) {
        sendToReactNative("🚫 Camera error: " + err.message);
      }
    }

    // ======== UTILITIES ========
    const flatten = (pts) => pts.flatMap(p => [p.x, p.y, p.z]);
    const maybeFlip = (arr) => {
      if (!FLIP_X) return arr;
      const out = arr.slice();
      for (let i = 0; i < out.length; i += 3) out[i] = 1 - out[i];
      return out;
    };
    const smooth = (arr, prevRef) => {
      if (!prevRef.value) { prevRef.value = arr.slice(); return arr; }
      for (let i = 0; i < arr.length; ++i)
        prevRef.value[i] = SMOOTHING_ALPHA * arr[i] + (1 - SMOOTHING_ALPHA) * prevRef.value[i];
      return prevRef.value.slice();
    };
    const zeroFrame = (n = 63) => new Array(n).fill(0);

    async function sendToBackend() {
      const body =
        HAND_MODE === "two"
          ? { right_hand: seqRight, left_hand: seqLeft, sequence_length: SEQ_LENGTH }
          : { right_hand: seqRight, sequence_length: SEQ_LENGTH };

      try {
        const res = await fetch(BACKEND_URL, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body),
        });

        const data = await res.json();
        console.log("🧠 Prediction:", data);
        sendToReactNative(JSON.stringify(data));
      } catch (err) {
        sendToReactNative("❌ Prediction error: " + err.message);
      }
    }

    // ======== MEDIAPIPE HANDS ========
    const hands = new Hands({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: HAND_MODE === "two" ? 2 : 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    hands.onResults((results) => {
      const now = Date.now();
      if (now - lastSampleTs < SAMPLE_INTERVAL_MS) return;
      lastSampleTs = now;

      let right = null,
        left = null;

      if (results.multiHandLandmarks && results.multiHandedness) {
        results.multiHandLandmarks.forEach((lm, i) => {
          const handType = results.multiHandedness[i].label;
          const flat = maybeFlip(flatten(lm));
          if (handType === "Right") right = smooth(flat, { value: prevSmoothR });
          if (handType === "Left") left = smooth(flat, { value: prevSmoothL });
        });
      }

      if (!right) right = prevSmoothR || zeroFrame();
      if (!left) left = prevSmoothL || zeroFrame();

      seqRight.push(right);
      seqLeft.push(left);
      if (seqRight.length > SEQ_LENGTH) seqRight.shift();
      if (seqLeft.length > SEQ_LENGTH) seqLeft.shift();

      if (seqRight.length === SEQ_LENGTH && now - lastSentTs > PREDICT_THROTTLE_MS) {
        lastSentTs = now;
        sendToBackend();
      }
    });

    async function init() {
      await setupCamera();
      cameraInstance = new Camera(videoElement, {
        onFrame: async () => await hands.send({ image: videoElement }),
        width: 640,
        height: 480,
      });
      cameraInstance.start();
    }

    init();

    function sendToReactNative(msg) {
      if (window.ReactNativeWebView?.postMessage)
        window.ReactNativeWebView.postMessage(msg);
      else console.log("RNBridge:", msg);
    }
  </script>
</body>
</html>
